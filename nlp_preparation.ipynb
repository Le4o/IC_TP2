{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "Convertendo o arquivo csv em um Dataframe para preparação da análise de dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/le4o/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/le4o/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/le4o/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package stopwords to /home/le4o/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Download nlkt packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         tweet_id   sentiment  \\\n",
       "0      1956967341       empty   \n",
       "1      1956967666     sadness   \n",
       "2      1956967696     sadness   \n",
       "3      1956967789  enthusiasm   \n",
       "4      1956968416     neutral   \n",
       "...           ...         ...   \n",
       "39995  1753918954     neutral   \n",
       "39996  1753919001        love   \n",
       "39997  1753919005        love   \n",
       "39998  1753919043   happiness   \n",
       "39999  1753919049        love   \n",
       "\n",
       "                                                 content  \n",
       "0      @tiffanylue i know  i was listenin to bad habi...  \n",
       "1      Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                    Funeral ceremony...gloomy friday...  \n",
       "3                   wants to hang out with friends SOON!  \n",
       "4      @dannycastillo We want to trade with someone w...  \n",
       "...                                                  ...  \n",
       "39995                                   @JohnLloydTaylor  \n",
       "39996                     Happy Mothers Day  All my love  \n",
       "39997  Happy Mother's Day to all the mommies out ther...  \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>Funeral ceremony...gloomy friday...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>wants to hang out with friends SOON!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>@dannycastillo We want to trade with someone w...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>1753918954</td>\n      <td>neutral</td>\n      <td>@JohnLloydTaylor</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>1753919001</td>\n      <td>love</td>\n      <td>Happy Mothers Day  All my love</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>1753919005</td>\n      <td>love</td>\n      <td>Happy Mother's Day to all the mommies out ther...</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>1753919043</td>\n      <td>happiness</td>\n      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>1753919049</td>\n      <td>love</td>\n      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "columns = ['tweet_id', 'sentiment', 'content']\n",
    "\n",
    "# Seed para os resultados da tokenização\n",
    "np.random.seed(500)\n",
    "\n",
    "# skip_blank_lines remove as possíveis linhas em branco\n",
    "data = pd.read_csv(r'data/tweet_emotions.csv', skip_blank_lines=True)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uppercase_to_lowercase(x): return str(x).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         tweet_id   sentiment  \\\n",
       "0      1956967341       empty   \n",
       "1      1956967666     sadness   \n",
       "2      1956967696     sadness   \n",
       "3      1956967789  enthusiasm   \n",
       "4      1956968416     neutral   \n",
       "...           ...         ...   \n",
       "39995  1753918954     neutral   \n",
       "39996  1753919001        love   \n",
       "39997  1753919005        love   \n",
       "39998  1753919043   happiness   \n",
       "39999  1753919049        love   \n",
       "\n",
       "                                                 content  \\\n",
       "0      [@, tiffanylue, i, know, i, was, listenin, to,...   \n",
       "1      [layin, n, bed, with, a, headache, ughhhh, ......   \n",
       "2          [funeral, ceremony, ..., gloomy, friday, ...]   \n",
       "3         [wants, to, hang, out, with, friends, soon, !]   \n",
       "4      [@, dannycastillo, we, want, to, trade, with, ...   \n",
       "...                                                  ...   \n",
       "39995                               [@, johnlloydtaylor]   \n",
       "39996               [happy, mothers, day, all, my, love]   \n",
       "39997  [happy, mother, 's, day, to, all, the, mommies...   \n",
       "39998  [@, niariley, wassup, beautiful, !, !, !, foll...   \n",
       "39999  [@, mopedronin, bullet, train, from, tokyo, th...   \n",
       "\n",
       "                                              text_final  \n",
       "0      ['tiffanylue', 'know', 'listenin', 'bad', 'hab...  \n",
       "1      ['layin', 'n', 'bed', 'headache', 'ughhhh', 'w...  \n",
       "2            ['funeral', 'ceremony', 'gloomy', 'friday']  \n",
       "3                     ['want', 'hang', 'friend', 'soon']  \n",
       "4      ['dannycastillo', 'want', 'trade', 'someone', ...  \n",
       "...                                                  ...  \n",
       "39995                                ['johnlloydtaylor']  \n",
       "39996                 ['happy', 'mother', 'day', 'love']  \n",
       "39997  ['happy', 'mother', 'day', 'mommy', 'woman', '...  \n",
       "39998  ['niariley', 'wassup', 'beautiful', 'follow', ...  \n",
       "39999  ['mopedronin', 'bullet', 'train', 'tokyo', 'gf...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>content</th>\n      <th>text_final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>[@, tiffanylue, i, know, i, was, listenin, to,...</td>\n      <td>['tiffanylue', 'know', 'listenin', 'bad', 'hab...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>[layin, n, bed, with, a, headache, ughhhh, ......</td>\n      <td>['layin', 'n', 'bed', 'headache', 'ughhhh', 'w...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>[funeral, ceremony, ..., gloomy, friday, ...]</td>\n      <td>['funeral', 'ceremony', 'gloomy', 'friday']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>[wants, to, hang, out, with, friends, soon, !]</td>\n      <td>['want', 'hang', 'friend', 'soon']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>[@, dannycastillo, we, want, to, trade, with, ...</td>\n      <td>['dannycastillo', 'want', 'trade', 'someone', ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>1753918954</td>\n      <td>neutral</td>\n      <td>[@, johnlloydtaylor]</td>\n      <td>['johnlloydtaylor']</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>1753919001</td>\n      <td>love</td>\n      <td>[happy, mothers, day, all, my, love]</td>\n      <td>['happy', 'mother', 'day', 'love']</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>1753919005</td>\n      <td>love</td>\n      <td>[happy, mother, 's, day, to, all, the, mommies...</td>\n      <td>['happy', 'mother', 'day', 'mommy', 'woman', '...</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>1753919043</td>\n      <td>happiness</td>\n      <td>[@, niariley, wassup, beautiful, !, !, !, foll...</td>\n      <td>['niariley', 'wassup', 'beautiful', 'follow', ...</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>1753919049</td>\n      <td>love</td>\n      <td>[@, mopedronin, bullet, train, from, tokyo, th...</td>\n      <td>['mopedronin', 'bullet', 'train', 'tokyo', 'gf...</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Removendo linhas em branco\n",
    "df = df.drop(df[(df.tweet_id == 0) | (df.sentiment == \"\") | (df.content == \"\")].index)\n",
    "\n",
    "# Convertendo txto em caixa alta para caixa baixa\n",
    "df['content'] = df['content'].apply(uppercase_to_lowercase)\n",
    "\n",
    "# Criando os tokens para o texto do tweet \n",
    "df['content'] = [word_tokenize(text) for text in df['content']]\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(df['content']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    df.loc[index,'text_final'] = str(Final_words)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ", 'brilliant': 567, 'windows': 4846, 'beard': 383, 'nurse': 3057, 'birmingham': 445, 'banquet': 350, 'bg': 431, 'blonde': 481, 'soundtrack': 4043, 'williams': 4840, 'montana': 2846, 'joey': 2287, 'silent': 3902, 'denny': 1169, 'romance': 3682, 'eve': 1461, 'twpp': 4589, 'murray': 2902, 'grocery': 1865, 'hoo': 2050, 'ram': 3529, 'lolz': 2564, 'somethin': 4014, 'corner': 969, 'campus': 658, 'coworker': 996, 'brew': 557, 'allah': 109, 'phil': 3276, 'oww': 3158, 'commence': 890, 'syrup': 4263, 'spotify': 4084, 'unlimited': 4645, 'jt': 2316, 'mtv': 2887, 'oi': 3091, 'helpful': 1987, 'plastic': 3327, 'chew': 759, 'university': 4641, 'lj': 2538, 'pint': 3310, 'guide': 1882, 'belt': 411, 'ahah': 73, 'limb': 2509, 'prevent': 3423, 'gg': 1766, 'sweaty': 4242, 'activity': 34, 'stitch': 4138, 'target': 4288, 'default': 1146, 'display': 1251, 'hung': 2099, 'looong': 2574, 'dresser': 1314, 'sumthin': 4202, 'whn': 4820, 'total': 4472, 'turkey': 4547, 'yard': 4942, 'yawn': 4943, 'monster': 2845, 'ten': 4322, 'approve': 209, 'announcement': 167, 'crown': 1029, 'nascar': 2930, 'kevin': 2350, 'route': 3694, 'mcdonald': 2708, 'nola': 3016, 'convo': 952, 'crack': 1002, 'ashleytisdale': 237, 'kay': 2341, 'anthony': 177, 'smart': 3966, 'tx': 4590, 'designer': 1183, 'mmitchelldaviss': 2814, 'roast': 3667, 'fabulous': 1522, 'diamond': 1207, 'relief': 3600, 'praise': 3403, 'whistle': 4818, 'eu': 1457, 'basically': 361, 'moore': 2852, 'bleach': 463, 'unfollowed': 4627, 'purpose': 3493, 'gots': 1828, 'hood': 2051, 'blade': 457, 'looool': 2575, 'pre': 3406, 'contract': 943, 'jerry': 2272, 'xxxxx': 4934, 'boost': 509, 'envy': 1432, 'theme': 4360, 'leopard': 2482, 'independent': 2161, 'compliment': 905, 'greenville': 1857, 'recital': 3566, 'ye': 4947, 'whack': 4806, 'twisted': 4574, 'sac': 3717, 'loveee': 2597, 'veggie': 4693, 'backstreetboys': 321, 'metallica': 2751, 'reward': 3646, 'taker': 4273, 'virtual': 4722, 'labor': 2404, 'td': 4299, 'freyalynn': 1689, 'task': 4289, 'matinee': 2694, 'ace': 22, 'actress': 36, 'restaurant': 3630, 'mystery': 2917, 'solve': 4009, 'basement': 358, 'square': 4089, 'tbh': 4297, 'bliss': 473, 'deadline': 1124, 'sao': 3745, 'paulo': 3228, 'proof': 3465, 'marketing': 2674, 'ginger': 1775, 'tila': 4415, 'ct': 1040, 'vehicle': 4694, 'capacity': 668, 'neil': 2963, 'cubicle': 1044, 'listening': 2527, 'fishies': 1608, 'suspend': 4235, 'query': 3505, 'jealousy': 2260, 'participate': 3205, 'lit': 2528, 'frozen': 1704, 'wk': 4868, 'ohhhhh': 3089, 'boys': 534, 'represent': 3617, 'morrison': 2858, 'difference': 1214, 'thankful': 4347, 'example': 1483, 'salvation': 3733, 'ne': 2948, 'disconnect': 1238, 'asshole': 243, 'spare': 4058, 'punch': 3485, 'neighborhood': 2961, 'convenient': 946, 'solo': 4007, 'parker': 3201, 'berry': 415, 'harddrive': 1932, 'giggle': 1773, 'piano': 3290, 'cord': 965, 'meant': 2717, 'likey': 2504, 'majorly': 2635, 'tournament': 4478, 'marginatasnaily': 2666, 'urge': 4659, 'pile': 3300, 'contribute': 944, 'flop': 1626, 'premier': 3411, 'trap': 4503, 'panera': 3186, 'hah': 1903, 'zach': 4989, 'nate': 2936, 'brave': 545, 'smooth': 3975, 'yah': 4938, 'digg': 1218, 'cutie': 1069, 'german': 1761, 'icecream': 2118, 'general': 1754, 'cinnamon': 807, 'crunch': 1032, 'clara': 815, 'craving': 1009, 'sample': 3738, 'barcelona': 353, 'teddy': 4310, 'xp': 4930, 'running': 3710, 'strap': 4153, 'cowboy': 995, 'gurl': 1893, 'journey': 2310, 'anniversary': 165, 'happiness': 1928, 'superman': 4214, 'dd': 1120, 'wander': 4757, 'wise': 4857, 'bible': 433, 'woop': 4889, 'sarah': 3747, 'slack': 3942, 'butterfly': 630, 'perfectly': 3256, 'jar': 2252, 'sparkly': 4059, 'highly': 2003, 'witty': 4865, 'lc': 2448, 'jst': 2315, 'moving': 2876, 'yellow': 4956, 'besties': 421, 'spoil': 4079, 'yumm': 4985, 'lily': 2507, 'restriction': 3631, 'etsy': 1456, 'martini': 2681, 'treatment': 4508, 'role': 3680, 'stubborn': 4168, 'industry': 2169, 'aaron': 2, 'amy': 147, 'pam': 3180, 'fabric': 1521, 'creative': 1014, 'cone': 917, 'sadden': 3721, 'lg': 2488, 'shite': 3865, 'katy': 2340, 'perry': 3262, 'loribartolozzi': 2581, 'wordpress': 4892, 'kidding': 2359, 'tues': 4538, 'neighbour': 2962, 'cherish': 756, 'visual': 4728, 'ogberry': 3084, 'woooo': 4887, 'ultimate': 4609, 'shallow': 3838, 'madness': 2622, 'obsess': 3069, 'ftw': 1710, 'wi': 4828, 'paramore': 3196, 'ireland': 2213, 'ranger': 3534, 'patience': 3221, 'lecture': 2464, 'bull': 609, 'wht': 4827, 'addictive': 45, 'thirty': 4379, 'markhoppus': 2675, 'wallace': 4751, 'sheesh': 3851, 'ping': 3307, 'pamper': 3181, 'hahahha': 1910, 'newbie': 2977, 'calendar': 645, 'bruce': 590, 'limo': 2514, 'soft': 4002, 'aaaah': 0, 'smoothie': 3976, 'carrier': 682, 'parallel': 3195, 'pakistan': 3176, 'fourth': 1668, 'context': 941, 'unite': 4636, 'unitechy': 4637, 'courthouse': 990, 'yest': 4961, 'admin': 47, 'drown': 1326, 'eek': 1382, 'serve': 3819, 'laker': 2411, 'pause': 3229, 'gi': 1769, 'danny': 1095, 'dougie': 1292, 'webcam': 4786, 'pjs': 3318, 'raid': 3523, 'tisdale': 4426, 'dig': 1217, 'ringtones': 3657, 'jason': 2253, 'install': 2189, 'engage': 1416, 'gf': 1765, 'mud': 2892, 'cage': 642, 'attach': 256, 'whew': 4814, 'baked': 336, 'benefit': 413, 'wassup': 4769, 'stat': 4114, 'particularly': 3207, 'lulu': 2610, 'baltimore': 343, 'junior': 2326, 'drizzle': 1324, 'natalietran': 2935, 'irvine': 2217, 'twitterville': 4585, 'loan': 2544, 'awaisnaseer': 287, 'tampa': 4281, 'promotion': 3464, 'subway': 4186, 'shrimp': 3884, 'mop': 2853, 'chipotle': 781, 'slam': 3943, 'depot': 1174, 'license': 2491, 'charlie': 737, 'chu': 798, 'plurk': 3343, 'nano': 2928, 'coulda': 980, 'deny': 1172, 'pineapple': 3306, 'pie': 3295, 'australian': 276, 'oprah': 3127, 'mam': 2643, 'vacuum': 4681, 'holla': 2030, 'yelyahwilliams': 4957, 'bagel': 329, 'kiddo': 2360, 'gilmore': 1774, 'xmen': 4925, 'origin': 3133, 'tommorrow': 4447, 'feedback': 1567, 'border': 512, 'carolina': 679, 'molly': 2831, 'hollywood': 2035, 'dayy': 1117, 'yayyy': 4946, 'ms': 2883, 'shine': 3859, 'soda': 4000, 'priceless': 3427, 'nom': 3017, 'todayy': 4436, 'victim': 4709, 'ross': 3691, 'mag': 2624, 'iz': 2234, 'ran': 3531, 'thrill': 4392, 'tw': 4554, 'ooc': 3111, 'lobster': 2546, 'painting': 3174, 'yayy': 4945, 'motivate': 2863, 'pitch': 3313, 'length': 2478, 'bookmark': 502, 'surf': 4223, 'shining': 3860, 'bowling': 530, 'cancelled': 662, 'avenue': 283, 'fluffy': 1631, 'eventually': 1465, 'planet': 3324, 'olive': 3099, 'gooood': 1820, 'education': 1380, 'selenagomez': 3801, 'amber': 138, 'pinch': 3304, 'pj': 3317, 'terri': 4329, 'coollike': 960, 'daft': 1076, 'gluten': 1794, 'united': 4638, 'kingdom': 2374, 'kk': 2382, 'vip': 4720, 'sunset': 4211, 'movin': 2875, 'comedy': 879, 'kilkenny': 2364, 'vegetarian': 4692, 'james': 2246, 'slim': 3957, 'weekly': 4795, 'motivation': 2864, 'noone': 3024, 'valley': 4682, 'fiddle': 1582, 'singer': 3915, 'jordan': 2305, 'active': 33, 'comm': 888, 'congratulation': 926, 'bracelet': 537, 'universe': 4640, 'mii': 2775, 'internal': 2200, 'pembsdave': 3248, 'tutorial': 4552, 'vent': 4696, 'producer': 3448, 'sausage': 3754, 'pix': 3315, 'icky': 2120, 'charlotte': 738, 'loved': 2595, 'glue': 1793, 'hungover': 2100, 'aim': 86, 'tall': 4280, 'format': 1659, 'success': 4187, 'pepper': 3251, 'positive': 3382, 'brittany': 574, 'espresso': 1451, 'ermm': 1443, 'mummy': 2898, 'bueno': 602, 'rio': 3658, 'goose': 1822, 'wifey': 4834, 'satisfied': 3751, 'demand': 1162, 'erin': 1441, 'content': 939, 'organize': 3132, 'billion': 438, 'greek': 1855, 'overcast': 3148, 'twitterific': 4581, 'reel': 3576, 'lov': 2592, 'mucho': 2891, 'stats': 4118, 'moi': 2830, 'closet': 837, 'rockin': 3675, 'thee': 4356, 'heyy': 1993, 'simpson': 3909, 'invisible': 2206, 'detroit': 1192, 'earring': 1362, 'clark': 817, 'celebs': 706, 'debit': 1131, 'daisy': 1078, 'sambennington': 3736, 'rogers': 3678, 'shadez': 3835, 'retire': 3636, 'grandparent': 1842, 'africa': 62, 'pin': 3303, 'victoria': 4711, 'bryan': 594, 'chiodos': 779, 'bat': 365, 'empire': 1408, 'attract': 263, 'bby': 376, 'scotland': 3769, 'handy': 1921, 'anatomy': 148, 'liking': 2505, 'classy': 821, 'simply': 3908, 'april': 212, 'thang': 4345, 'belong': 409, 'society': 3998, 'dashboard': 1102, 'jenn': 2265, 'tango': 4283, 'icon': 2121, 'fairly': 1532, 'bak': 334, 'parody': 3203, 'ver': 4699, 'clip': 833, 'volume': 4737, 'unemployed': 4623, 'unique': 4634, 'equal': 1437, 'prejudice': 3410, 'mandyyjirouxx': 2653, 'respect': 3626, 'mit': 2806, 'selection': 3799, 'discount': 1239, 'mozart': 2878, 'horny': 2062, 'hooked': 2054, 'solangeknowles': 4005, 'beauty': 387, 'lolll': 2562, 'shannon': 3842, 'edition': 1379, 'deb': 1128, 'nathanfillion': 2938, 'studying': 4173, 'polaroid': 3357, 'sneeze': 3983, 'vanilla': 4688, 'standard': 4102, 'joeymcintyre': 2288, 'milkshake': 2784, 'politics': 3362, 'java': 2255, 'relaxing': 3597, 'dia': 1205, 'expert': 1505, 'playoff': 3334, 'brooke': 582, 'indie': 2166, 'leeds': 2466, 'certainly': 716, 'limited': 2513, 'cheesy': 751, 'denial': 1167, 'lilyroseallen': 2508, 'ap': 191, 'union': 4633, 'fur': 1725, 'colin': 863, 'bonfire': 497, 'george': 1759, 'amanda': 132, 'en': 1412, 'circle': 808, 'backround': 320, 'router': 3695, 'kg': 2355, 'ski': 3932, 'aight': 85, 'dawson': 1115, 'creek': 1017, 'wax': 4779, 'cloudconnected': 842, 'auntie': 270, 'argentina': 218, 'crochet': 1026, 'slide': 3954, 'girls': 1779, 'terminal': 4327, 'crisp': 1025, 'itch': 2225, 'krystynchong': 2397, 'ahahaha': 75, 'lemonade': 2477, 'mixed': 2812, 'boob': 500, 'needa': 2956, 'leadership': 2452, 'patrick': 3224, 'zac': 4988, 'fella': 1572, 'category': 694, 'pride': 3428, 'shelf': 3853, 'ci': 801, 'crystal': 1037, 'steel': 4126, 'british': 572, 'liz': 2537, 'directory': 1228, 'rick': 3650, 'greggrunberg': 1861, 'spicy': 4071, 'boom': 504, 'mah': 2628, 'favor': 1559, 'paw': 3230, 'mainly': 2632, 'thin': 4371, 'correction': 972, 'dawnrichard': 1114, 'oo': 3110, 'admire': 48, 'mann': 2656, 'animation': 159, 'vast': 4689, 'oot': 3119, 'carrie': 681, 'cupboard': 1052, 'noooooooo': 3030, 'cub': 1042, 'dessert': 1189, 'papa': 3190, 'myrtle': 2915, 'nana': 2926, 'cassie': 689, 'natalie': 2934, 'marc': 2663, 'friendster': 1698, 'cent': 709, 'bailey': 333, 'ann': 162, 'liver': 2533, 'jazz': 2257, 'teenage': 4313, 'crutch': 1034, 'aplusk': 194, 'crib': 1021, 'native': 2940, 'warp': 4764, 'commentary': 892, 'mu': 2888, 'excitement': 1490, 'itt': 2229, 'goody': 1817, 'tt': 4534, 'cooking': 956, 'brad': 538, 'vinegar': 4718, 'cozy': 999, 'chelsea': 753, 'dane': 1091, 'cherry': 757, 'chrisettefan': 792, 'movement': 2873, 'chic': 761, 'ellen': 1396, 'index': 2162, 'cyrus': 1072, 'angle': 156, 'therealsavannah': 4364, 'gasp': 1745, 'alien': 106, 'whoo': 4824, 'carpet': 680, 'dub': 1335, 'legit': 2472, 'purple': 3492, 'cont': 935, 'las': 2425, 'kool': 2394, 'robert': 3670, 'juss': 2330, 'champagne': 724, 'blessed': 468, 'sh': 3833, 'utah': 4673, 'dreambears': 1312, 'fatty': 1555, 'hawaii': 1945, 'bash': 359, 'selena': 3800, 'frame': 1671, 'sherrieshepherd': 3855, 'francisco': 1673, 'maddie': 2621, 'consist': 930, 'lem': 2475, 'grape': 1845, 'matrix': 2695, 'jennifalconer': 2268, 'choir': 786, 'bbl': 374, 'goat': 1802, 'legal': 2470, 'lovato': 2593, 'twin': 4572, 'youu': 4975, 'mash': 2683, 'loll': 2561, 'bebo': 388, 'messenger': 2748, 'heidimontag': 1981, 'jungle': 2325, 'noufah': 3047, 'pasta': 3216, 'explain': 1507, 'hahahah': 1907, 'emzyjonas': 1411, 'johnmaine': 2293, 'necklace': 2954, 'community': 895, 'lmfao': 2541, 'romantic': 3683, 'novel': 3048, 'mamma': 2646, 'dip': 1224, 'nowadays': 3050, 'tasty': 4291, 'chart': 740, 'cow': 994, 'mighty': 2772, 'meat': 2718, 'construction': 934, 'hmv': 2020, 'sympathy': 4260, 'hollie': 2032, 'okayy': 3095, 'superstar': 4216, 'grub': 1875, 'hardcore': 1931, 'awkward': 299, 'foreign': 1652, 'utter': 4674, 'hahahahaha': 1909, 'lane': 2418, 'sn': 3978, 'towel': 4481, 'thier': 4369, 'common': 894, 'coco': 854, 'awwwh': 304, 'liam': 2489, 'wooo': 4886, 'mushroom': 2906, 'muah': 2889, 'aiden': 84, 'pond': 3363, 'bow': 528, 'theellenshow': 4357, 'aye': 309, 'flavor': 1618, 'input': 2180, 'nugget': 3054, 'mcr': 2711, 'ke': 2342, 'owe': 3154, 'mitchel': 2808, 'crisis': 1024, 'procrastination': 3446, 'culture': 1050, 'ja': 2235, 'nm': 3008, 'dancer': 1089, 'elle': 1395, 'checkin': 746, 'sweater': 4241, 'amo': 142, 'unclerush': 4620, 'ramen': 3530, 'kenny': 2349, 'pinky': 3309, 'gem': 1753, 'notification': 3045, 'spamming': 4056, 'fil': 1589, 'promo': 3462, 'clearly': 828, 'apologize': 195, 'jeremy': 2270, 'declare': 1137, 'login': 2557, 'trader': 4487, 'chica': 762, 'select': 3798, 'moonfrye': 2851, 'montreal': 2848, 'ftsk': 1709, 'tot': 4471, 'oyfreakinvey': 3161, 'surprising': 4227, 'celeb': 702, 'colorado': 869, 'chap': 729, 'ummmm': 4615, 'nutella': 3060, 'readin': 3548, 'katie': 2339, 'thisisryanross': 4380, 'ni': 2985, 'hence': 1988, 'backpack': 319, 'reckon': 3567, 'overcome': 3149, 'twitterer': 4579, 'xoxox': 4929, 'cleaner': 824, 'hobby': 2022, 'homee': 2039, 'wolf': 4876, 'photography': 3283, 'pritchard': 3436, 'eatin': 1368, 'forest': 1653, 'surprisingly': 4228, 'mutual': 2913, 'bakery': 337, 'cld': 822, 'tradition': 4488, 'mmmmm': 2817, 'braid': 541, 'julia': 2321, 'wu': 4920, 'sheep': 3850, 'sonny': 4025, 'italian': 2223, 'disco': 1237, 'draft': 1302, 'gran': 1837, 'sketch': 3931, 'mm': 2813, 'kellie': 2346, 'grace': 1831, 'elvis': 1398, 'ist': 2222, 'wikipedia': 4837, 'therefore': 4365, 'voicemail': 4733, 'stylish': 4180, 'dirt': 1229, 'brb': 547, 'spoon': 4081, 'punk': 3487, 'leah': 2454, 'tommy': 4448, 'innocent': 2179, 'awesomeness': 294, 'denmark': 1168, 'await': 288, 'omgosh': 3104, 'piggy': 3299, 'thnx': 4382, 'tut': 4550, 'seek': 3796, 'wossy': 4904, 'tink': 4421, 'offf': 3077, 'lion': 2520, 'md': 2713, 'fellow': 1573, 'giveaway': 1783, 'puzzle': 3497, 'unexpected': 4624, 'average': 284, 'youuu': 4976, 'noble': 3010, 'twiiter': 4570, 'scottish': 3771, 'accent': 14, 'hughsbeautiful': 2090, 'thisstarchild': 4381, 'smiley': 3971, 'inspirational': 2186, 'riot': 3659, 'retro': 3637, 'greet': 1858, 'bass': 363, 'hayes': 1948, 'appeal': 199, 'learning': 2458, 'fitness': 1610, 'hehehehe': 1980, 'rb': 3542, 'anyhoo': 183, 'ciara': 802, 'brighton': 566, 'allison': 113, 'entirely': 1430, 'twas': 4555, 'opening': 3122, 'drummer': 1330, 'susan': 4232, 'attic': 261, 'chillen': 771, 'melissa': 2735, 'liquid': 2522, 'patron': 3225, 'lotion': 2588, 'souljaboytellem': 4041, 'grease': 1851, 'string': 4163, 'kim': 2367, 'victory': 4712, 'corona': 970, 'jamba': 2245, 'monica': 2842, 'jesse': 2275, 'tweeples': 4558, 'andrea': 149, 'spent': 4070, 'lovee': 2596, 'doug': 1291, 'farmer': 1548, 'author': 277, 'tropical': 4520, 'heading': 1956, 'hhrs': 1996, 'rocket': 3674, 'mocha': 2822, 'iowa': 2210, 'scout': 3773, 'wellington': 4801, 'awesomness': 295, 'willy': 4842, 'combine': 873, 'legend': 2471, 'former': 1660, 'champion': 725, 'tooooo': 4460, 'moan': 2820, 'scroll': 3779, 'yaay': 4937, 'rp': 3699, 'nikkibenz': 2998, 'sarmy': 3748, 'spock': 4078, 'prep': 3413, 'shaun': 3847, 'sas': 3749, 'smut': 3977, 'atmosphere': 255, 'hayley': 1950, 'robluketic': 3672, 'acc': 13, 'verwon': 4703, 'kfc': 2354, 'specific': 4064, 'anoop': 172, 'modern': 2828, 'volleyball': 4736, 'balloon': 342, 'chilling': 774, 'jane': 2248, 'nacho': 2919, 'princesssuperc': 3431, 'jp': 2312, 'yt': 4979, 'forth': 1662, 'th': 4341, 'acoustic': 29, 'poker': 3355, 'starship': 4107, 'frankie': 1675, 'reaction': 3545, 'daniel': 1094, 'owl': 3155, 'application': 203, 'boredd': 515, 'loveeee': 2598, 'realbillbailey': 3552, 'chilli': 772, 'wooooo': 4888, 'leeprovoost': 2467, 'dayyyy': 1118, 'ay': 308, 'musicmonday': 2910, 'nikki': 2997, 'tester': 4335, 'blessing': 469, 'prof': 3452, 'jennamadison': 2266, 'norm': 3033, 'belgian': 402, 'kudos': 2398, 'dutch': 1349, 'nk': 3005, 'missxmarisa': 2803, 'kyleandjackieo': 2400, 'hoppusday': 2061, 'cult': 1049, 'jtimberlake': 2317, 'hee': 1974, 'duper': 1347, 'laterz': 2430, 'babygirlparis': 313, 'hoedown': 2025, 'aussiecynic': 273, 'iantalbot': 2116, 'woah': 4874, 'lookout': 2573, 'heavenly': 1970, 'thas': 4352, 'logies': 2556, 'littlefletcher': 2531, 'comedian': 878, 'juddday': 2318, 'tnx': 4432, 'bom': 493, 'rosehwang': 3690, 'knit': 2386, 'eagle': 1356, 'creativity': 1015, 'swedish': 4244, 'nks': 3007, 'goodnite': 1816, 'comedyqueen': 880, 'bali': 340, 'rad': 3521, 'mend': 2741, 'crafty': 1003, 'greeting': 1859, 'mraz': 2880, 'ph': 3273, 'spongebob': 4080, 'vol': 4735, 'tiff': 4411, 'utterhip': 4675, 'teehee': 4312, 'holland': 2031, 'phrase': 3286, 'vicky': 4708, 'dum': 1342, 'nz': 3067, 'photographer': 3282, 'explanation': 1508, 'laze': 2445, 'choc': 783, 'starwars': 4112, 'fudgecrumpet': 1716, 'csi': 1039, 'alpha': 125, 'gang': 1738, 'robbie': 3669, 'masterballerina': 2689, 'greece': 1853, 'archuleta': 215, 'dannywood': 1097, 'hurray': 2104, 'python': 3499, 'starwarsday': 4113, 'brush': 593, 'yaaaay': 4936, 'iamjonathancook': 2114, 'aloha': 119, 'thelonely': 4358, 'kalebnation': 2335, 'jennettemccurdy': 2267, 'sho': 3867, 'lucas': 2604, 'bamboozle': 344, 'pacman': 3168, 'blokeslib': 480, 'muse': 2904, 'macquid': 2619, 'jackman': 2240, 'olivia': 3100, 'rail': 3524, 'tweetphoto': 4566, 'cody': 858, 'michaelmagical': 2761, 'poet': 3351, 'sensation': 3809, 'deed': 1142, 'dedication': 1140, 'relaxin': 3596, 'runner': 3709, 'midwest': 2770, 'scottrmcgrew': 3772, 'omj': 3105, 'snore': 3989, 'pudding': 3480, 'loic': 2559, 'decorate': 1138, 'mommas': 2835, 'funn': 1723, 'leigh': 2474, 'sigjeans': 3897, 'johncmayer': 2291, 'mothersday': 2861, 'michaelsheen': 2762, 'moms': 2838, 'jojowright': 2298, 'canuck': 666, 'prosper': 3470, 'newjabbakidz': 2980, 'mums': 2899, 'mayer': 2704, 'margarita': 2665, 'brianmcnugget': 559, 'miller': 2785, 'yao': 4941, 'madre': 2623, 'startrek': 4109, 'correspondent': 973, 'kirk': 2375, 'mariahcarey': 2669, 'zachary': 4990, 'quinto': 3511, 'wango': 4758, 'defend': 1147, 'sanctuary': 3740, 'sanctuarysunday': 3741, 'sykes': 4259, 'panty': 3189, 'pine': 3305, 'skit': 3938, 'celebration': 704, 'pong': 3364, 'aclockworktoad': 28, 'mommys': 2837, 'johnlloydtaylor': 2292, 'bradiewebbstack': 540, 'jimmyfallon': 2281, 'ztnewetnorb': 4998, 'iwonder': 2233, 'howd': 2077, 'iget': 2128, 'heycassadee': 1992, 'bradie': 539, 'devyra': 1200, 'debbiefletcher': 1130, 'jasonbradbury': 2254, 'pcsketch': 3236, 'jpmizdelicious': 2313, 'aloliver': 120}\n  (0, 4387)\t0.21276868407848812\n  (0, 4372)\t0.20883426707712877\n  (0, 3797)\t0.25622022455344007\n  (0, 3468)\t0.34160476782694577\n  (0, 3070)\t0.39166323179135953\n  (0, 2501)\t0.1649138857340599\n  (0, 2205)\t0.4035022469281801\n  (0, 1977)\t0.34477195486502166\n  (0, 1606)\t0.23410268914027246\n  (0, 309)\t0.374977077136555\n  (0, 239)\t0.2666173225322615\n  (1, 4900)\t0.4809421772035329\n  (1, 4790)\t0.4344526764953884\n  (1, 4601)\t0.3411997510632412\n  (1, 2890)\t0.26770820912269827\n  (1, 2011)\t0.4433171749242612\n  (1, 1677)\t0.4419620132235245\n  (2, 4656)\t0.5883727199658796\n  (2, 2136)\t0.3685745602505314\n  (2, 1470)\t0.4609820944212517\n  (2, 1070)\t0.55268964578602\n  (3, 4913)\t0.6230141773246106\n  (3, 456)\t0.7822105438131978\n  (4, 3801)\t0.5882955246749993\n  (4, 3345)\t0.576301877492973\n  :\t:\n  (27995, 4759)\t0.17642391677124628\n  (27995, 4548)\t0.2553265172658483\n  (27995, 3236)\t0.38206210269611757\n  (27995, 3106)\t0.1742975334907227\n  (27995, 2558)\t0.36927799922391785\n  (27995, 2141)\t0.31745233746469653\n  (27995, 2038)\t0.1870072333063656\n  (27995, 1116)\t0.14038886520239383\n  (27995, 632)\t0.23919201129322443\n  (27995, 623)\t0.29441751870678684\n  (27995, 480)\t0.37733378467700623\n  (27995, 435)\t0.23524913294604607\n  (27995, 144)\t0.1875560897655288\n  (27995, 38)\t0.2423101413756464\n  (27996, 4963)\t0.37524386563287176\n  (27996, 2422)\t0.6249648344340852\n  (27996, 389)\t0.47402935463169216\n  (27996, 227)\t0.4938695859972927\n  (27998, 3708)\t0.4490691135624104\n  (27998, 2501)\t0.29813981520579397\n  (27998, 1570)\t0.5216610087111854\n  (27998, 1445)\t0.6613012731151774\n  (27999, 3766)\t0.42415189518968077\n  (27999, 3498)\t0.7680689920308539\n  (27999, 2872)\t0.47975534732581165\n"
     ]
    }
   ],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['text_final'], df['sentiment'], test_size=0.3)\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(df['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "\n",
    "print(Tfidf_vect.vocabulary_)\n",
    "print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values():\n",
    "    return Train_X_Tfidf, Tfidf_vect, Test_X, Train_Y, Test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}